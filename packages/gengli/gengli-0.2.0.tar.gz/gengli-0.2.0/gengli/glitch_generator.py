"""
gengli.glitch_generator
=======================
	Implementation of the class ``glitch_generator``. The class does everything you wish (and more) with the glitch generation...
"""

from .ctgan import model
import os
import torch
import numpy as np
import time
from .utils import compute_distance_matrix, resample_glitch, low_pass_glitch, rescale_glitch
import itertools
from tqdm import tqdm
import ray
import inspect
import scipy.signal


################################################################################################
################################################################################################

# FIXME: the sampling rate of raw GANN's output is hardcoded to be 4096 Hz. Is that fine? If not, where's the best place for this?

class glitch_generator():
	"""
	Class to generate a glitch. It creates an instance of the network at initialization and offers a number of method to sample random glitches for the network.
	"""
	def __init__(self, detector = None, weight_file = None, input_size = 100):
		"""
		Instantiate the ctgan and initialize a number of useful attributes

		Parameters
		----------
		detector: str
			String with the detector name (only used to load a pre-fitted model). Accepted values are "H1" or "L1".

		weight_file: str
			Path with a file holding valid weights for the generator

		input_size: int
			Input for the random vector. It is **not** advised to change the default value (100).
		"""
		self.allowed_types = ['blip']

		if not isinstance(weight_file, str):
			if not isinstance(detector, str):
				raise RuntimeError("If no file for the weights of the generator is given, an iterferometer must be specified to load the proper default model")
			assert str(detector).upper() in ['H1', 'L1'], "`detector` variable must be either 'H1' or 'L1', '{}' given".format(detector)
			dir_weights = os.path.dirname(inspect.getfile(glitch_generator))+"/ctgan/weights/"
			self.weight_file = dir_weights+'blip_'+str(detector).upper()+'_CTGAN_state_G.pth'
		else:
			self.weight_file = weight_file

		# Check cuda device
		if torch.cuda.is_available():
			self.device = torch.device("cuda:0")
		else:
			self.device = torch.device("cpu")

		# TODO: Deal better with all this magic numbers...

		# Length of noise
		self.input_size = input_size

		# Number of channels (to be set when loading the model)
		self.num_channel_G = None

		# Setting the D and G with random weigths
		self.load_generator_weights(self.weight_file)

		# Some benchmark initialization
		self.benchmark_set = None
		self.benchmark_srate = None
		self.distance_matrix = None
		self.metric_hist = None

		self.len_raw_glitch = len(self.get_glitch())

		return

	def load_generator_weights(self, weight_file):
		"""
		Loads the weight of the generator network
		"""
		if not os.path.exists(weight_file):
			msg = "Unable to find the weights for the generator! File '{}' does not exist".format(weight_file)
			raise FileNotFoundError(msg)
		try:
			dict_weights = torch.load(weight_file, map_location = self.device)
			self.num_channel_G = dict_weights['conv5.2.running_var'].shape[0]
		except (KeyError, ValueError):
			raise ValueError("The input file for the weights is not valid. Are you sure it is suitable for the generator?")

		self.netG = model.GenerativeNet(self.num_channel_G)
		self.netG.load_state_dict(dict_weights)
		self.netG.eval()
		self.netG = self.netG.to(self.device)
		return

	def _check_glitch_type(self, glitch_type):
		"Checks whether the given glitch type is allowed"
		if glitch_type.lower() not in self.allowed_types:
			msg = "Wrong type '{}' for the glitch specified. Allowed types are: '{}'".format(glitch_type, self.allowed_types) 
			raise ValueError(msg)
		return True

	def get_glitch(self, n_glitches = 1, srate = 4096., snr = None, glitch_type='Blip', seed = None, alpha = 0.25, fhigh = None):
		"""
		Returns a time domain glitch of the given type, as a :class:`~numpy:numpy.ndarray`.
		A glitch amounts to the excess power of a *whithened timeseries* and it is what is generated by the GANN (modulo scaling, windowing and resampling).
		
		So far only *blip* glitches are implemented but stay tuned: more glitches will come soon.
		
		Parameters
		----------
	
		n_glitches: int
			The number of glitches to generate
			
		srate: float
			Sampling rate for the given glitch
		
		snr: float, :class:`~numpy:numpy.ndarray`
			Signal-to-noise (snr) ratio of the returned glitches. The snr is computed *according to the lalsuite white noise normalization*.
			If None, no rescaling will be performed

		glitch_type: str
			Type for the glitch to generate. The available types are available with `glitch_generator.allowed_types`
			
		seed: int
			Seed for the random glitch generation. If `None` no seed is set.
		
		alpha: float
			Shape parameter of the Tukey window, as defined in :class:`~scipy:scipy.signal.windows.tukey`.
			If None, no windowing is performed
		
		fhigh: float
			High frequency cutoff for the low pass filter. If `None`, no filtering will be performed
			Usually, a blip glitch has a high frequency cutoff of `250 Hz`.

		Returns
		-------
	
		glitch: :class:`~numpy:numpy.ndarray`
			An array holding the glitch. Each row holds a different glitch
		"""
		#TODO: set a lowpass filter, to remove some high frequency garbage?
		self._check_glitch_type(glitch_type)
		
		if isinstance(seed, int): torch.manual_seed(seed)
		
		fixed_noise = torch.randn((n_glitches, 1, self.input_size), device=self.device)
		with torch.no_grad():
			glitch = self.netG(fixed_noise).detach().cpu().numpy()
			glitch = np.asarray(np.squeeze(glitch))
		
		if srate != 4096.: glitch = resample_glitch(glitch, 4096., srate)

			#Lowpass
		glitch = low_pass_glitch(glitch, fhigh, srate)

			#rescaling
		glitch = rescale_glitch(glitch, snr, srate)
		
			#widowing
		if alpha:
			window = scipy.signal.windows.tukey(glitch.shape[-1], alpha=alpha, sym=True)
			glitch = glitch * window
		
		return glitch

	def initialize_benchmark_set(self, n_glitches=10, srate=4096., glitch_type='Blip'):
		"""
		Initialize an internal set of glitches. They will be used to compute the anomaly score of each newly generated glitch.
		See :ref:`Generating glitches in a confidence interval` for more information.

		Parameters
		----------
		n_glitches: int
			Size of the glitch benchmark set (i.e. number of glitch to include in the set)

		rate: float
			Sampling rate for the glitch

		glitch_type: str
			Type for the glitch to generate. The available types are available with `glitch_generator.allowed_types`

		Returns
		-------
		benchmark_set: :class:`~numpy:numpy.ndarray`
			Generated benchmark set for the glitches
		"""
		self._check_glitch_type(glitch_type)

		self.benchmark_srate = srate

		start = time.time()
		self.benchmark_set = self.get_glitch(n_glitches, srate = srate, glitch_type = glitch_type)
		# print('Initializing data set took {} seconds.'.format(np.round(time.time() - start, 6))) #DEBUG print

		ray.init(log_to_driver=False)
		self.distance_matrix = compute_distance_matrix(self.benchmark_set, self.benchmark_set)
		ray.shutdown()

			# creating an histogram of distances
			# (ugly, but works...)
		self.metric_hist = np.array([ self.distance_matrix[i, j, :] for i, j in itertools.product(range(n_glitches), range(n_glitches)) if i>j])  # (N*(N-1)/2, 3)

		print("Benchmark set initialized")
		return self.benchmark_set

	def get_len_glitch(self, srate = 4096.):
		"""
		Computes the length of the generated glitch with a given sampling rate
		
		Parameters
		----------
		srate: float
			Sampling rate of the glitch

		Returns
		-------
		length: int
			Length of the time grid th glitch is evaluated at
		"""
		return int(self.len_raw_glitch*srate/4096.)

	def get_fft_grid(self, srate = 4096.):
		"""
		Returns the frequency grid on which the glitch is evaluated after the rfft (as in `np.fft.rfft`)
		Wrapper to `np.fft.rfftfreq`.

		Parameters
		----------
		srate: float
			Sampling rate of the glitch

		Returns
		-------
		f_grid: :class:`~numpy:numpy.ndarray`
			Frequency grid on which the frequency domain glitch is evaluated
		"""
		return np.fft.rfftfreq(self.get_len_glitch(srate), 1./srate)


	def get_glitch_confidence_interval(self, percentiles, n_glitches = 1, srate = 4096., snr = None, glitch_type='Blip', seed = None, alpha = 0.25, fhigh = None):
		"""
		Returns glitch(es) in the given interval of percentiles by calling iteratively :func:`get_glitch`.
		A glitch falls in a given percentile interval if several measures of distance between the glitch and a benchmark set lie in the given percentile interval of their typical values. The typical values are computed by considering all the pairs of distances between elements in the benchmark set. See :ref:`Generating glitches in a confidence interval` for more information.

		If the benchmark set is not initialized, it will be initialized with defaults arguments, calling :func:`initialize_benchmark_set`.	

		Parameters
		----------
		percentiles: tuple
			Percentile interval for the generated glitches.

		n_glitches: int
			The number of glitches to generate

		srate: float
			Sampling rate for the given glitch
		
		snr: float, :class:`~numpy:numpy.ndarray`
			Signal-to-noise (snr) ratio of the returned glitches. The snr is computed *according to the lalsuite white noise normalization*.
			If None, no rescaling will be performed

		glitch_type: str
			Type for the glitch to generate. The available types are available with `glitch_generator.allowed_types`
			
		seed: int
			Seed for the random glitch generation. If `None` no seed is set.
		
		alpha: float
			Shape parameter of the Tukey window, as defined in :class:`~scipy:scipy.signal.windows.tukey`.
			If None, no windowing is performed
		
		fhigh: float
			High frequency cutoff for the low pass filter. If `None`, no filtering will be performed
			Usually, a blip glitch has a high frequency cutoff of `250 Hz`.		

		Returns
		-------
	
		glitch: :class:`~numpy:numpy.ndarray`
			An array holding the anomaly glitches. Each row holds a different glitch

		"""
		# initializing the benchmark_set (if it is the case AND if it's not already initialized)
		if isinstance(percentiles, (list, tuple)) and srate != self.benchmark_srate:
			self.initialize_benchmark_set(srate=srate, glitch_type=glitch_type)

			#extracting args from kwargs
		glitches = self.get_glitch(n_glitches, srate = srate, seed = seed)
		
			# Computing confidence metric and generating glitches (if it's the case)
		if isinstance(percentiles, tuple):
			glitches = np.atleast_2d(glitches)

			ray.init(log_to_driver=False)
			glitches_ok = []

				# tqdm stuff
			def dummy_it():
				while True:
					yield

			out_str='Generated {}/{} glitches in the confidence interval [{},{}]'
			pbar = tqdm(dummy_it(), desc = out_str.format(0,n_glitches, *percentiles))

			for _ in pbar:			
				new_distance_matrix = compute_distance_matrix(self.benchmark_set, glitches)  # (N_benchmark, N_glitches, 3)

				new_distance_avg = np.mean(new_distance_matrix, axis = 0)  # (N_glitches, 3)

				percentiles_ = np.percentile(self.metric_hist, [*percentiles], axis =0)  # (2,3)

				ids_ok = np.logical_and(new_distance_avg>percentiles_[0, :], new_distance_avg<percentiles_[1, :])  # (N_glitches, 3)
				ids_ok = np.sum(ids_ok, axis =1).astype(bool)  # (N_glitches, )

				if len(ids_ok)>0:
					glitches_ok.append(glitches[ids_ok, :])

				if len(glitches_ok)>0:
					N = np.sum([g.shape[0] for g in glitches_ok])
					pbar.set_description(out_str.format(N, n_glitches, *percentiles))
					if N>= n_glitches: break

				glitches = np.atleast_2d(self.get_glitch(n_glitches, srate = srate))

			glitches = np.concatenate(glitches_ok, axis =0)[:n_glitches, :]
			glitches = np.squeeze(glitches)

			ray.shutdown()
			
		###
		# Doing the post-processing
		
			#Lowpass
		glitches = low_pass_glitch(glitches, fhigh, srate)

			#rescaling
		glitches = rescale_glitch(glitches, snr, srate)
		
			#widowing
		if alpha:
			window = scipy.signal.windows.tukey(glitches.shape[-1], alpha=alpha, sym=True)
			glitches = glitches * window
		
		return glitches






