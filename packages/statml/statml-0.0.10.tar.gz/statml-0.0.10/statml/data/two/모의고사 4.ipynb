{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 라이브러리 호출\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.warn(\"once\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, skew\n",
    "# 선형모델을 추정하는 라이브러리\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "from patsy import dmatrices\n",
    "color = sns.color_palette()\n",
    "\n",
    "pd.set_option('display.float_format','{:,.4f}'.format) # 소수점 2번째 자리까지 표현\n",
    "pd.set_option('display.max_columns', None) # 모든 컬럼 표시\n",
    "pd.set_option('display.max_colwidth', -1) # 컬럼내용 전체 표시\n",
    "\n",
    "#Graph에 한글을 표시하기 위한 코드\n",
    "import matplotlib\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "# font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "font_name = font_manager.FontProperties(fname=\"/home/spa/.local/share/Trash/files/one/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\\\n",
    "    \n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 정형 데이터마이닝 (사용 데이터 : weatherAUS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) 데이터의 요약값을 보고 NA값이 10,000개 이상인 열을 제외하고 남은 변수 중 NA값이 있는 행을 제거하시오. \n",
    "###     그리고 AUS 데이터의 Date 변수를 Date형으로 변환하고, \n",
    "###     전처리가 완료된 weatherAUS 데이터를 train(70%), test(30%) 데이터로 분할하시오.\n",
    "###     (set.seed(6789)를 실행한 후 데이터를 분할하시오.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/weatherAUS.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['WindDir9am', 'Pressure9am', 'Pressure3pm', \"Cloud9am\", \"Cloud3pm\"]\n",
    "df = df.drop(columns = drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop(columns = 'RainTomorrow'))\n",
    "y = df['RainTomorrow'] = np.where(df['RainTomorrow'] == 'Yes', 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 6789)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) train 데이터로 종속변수인 RainTomorrow(다음날의 강수 여부)를 예측하는 분류모델을 \n",
    "###     3개 이상 생성하고 test 데이터에 대한 예측값을 csv파일로 각각 제출하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "lr = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Date'] = X_train['Date'].map(dt.datetime.toordinal)\n",
    "X_test['Date'] = X_test['Date'].map(dt.datetime.toordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "lr_y_pred = lr.predict(X_test)\n",
    "# lr_y_pred.to_csv('lr_y_pred.csv')\n",
    "# lr.score(lr_y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(lr_y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "# rf_y_pred.to_csv('rf_y_pred.csv')\n",
    "# rf.score(rf_y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(rf_y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train=np.where(rf_y_pred=='No', 0, 1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_train, y_train)\n",
    "xgb_y_pred = xgb.predict(X_test)\n",
    "# xgb_y_pred.to_csv('svc_y_pred.csv')\n",
    "# xgb.score(svc_y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(xgb_y_pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, lr_y_pred)\n",
    "print('오차 행렬:\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_pred = pd.Series(lr_y_pred)\n",
    "lr_y_pred.loc[lr_y_pred == 'Yes'] = 1\n",
    "lr_y_pred.loc[lr_y_pred == 'No'] = 0\n",
    "lr_y_pred = lr_y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, lr_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, rf_y_pred)\n",
    "print('오차 행렬:\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_y_pred = pd.Series(rf_y_pred)\n",
    "rf_y_pred.loc[rf_y_pred == 'Yes'] = 1\n",
    "rf_y_pred.loc[rf_y_pred == 'No'] = 0\n",
    "rf_y_pred = rf_y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, rf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(y_test, xgb_y_pred)\n",
    "print('오차 행렬:\\n', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_y_pred = pd.Series(xgb_y_pred)\n",
    "xgb_y_pred.loc[xgb_y_pred == 'Yes'] = 1\n",
    "xgb_y_pred.loc[xgb_y_pred == 'No'] = 0\n",
    "xgb_y_pred = xgb_y_pred.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, xgb_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test.loc[y_test == 'Yes'] = 1\n",
    "#y_test.loc[y_test == 'No'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr.decision_function(X_test))\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC 곡선')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR (재현율)')\n",
    "# 0 근처의 임계값을 찾습니다.\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize = 10,\n",
    "        label = '임계값 0', fillstyle = 'none', c = 'k', mew = 2)\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC 곡선')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR (재현율)')\n",
    "# 0 근처의 임계값을 찾습니다.\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize = 10,\n",
    "        label = '임계값 0', fillstyle = 'none', c = 'k', mew = 2)\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "rf_auc = roc_auc_score(y_test, rf.predict_proba(X_test)[:, 1])\n",
    "# svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print('랜덤 포레스트의 AUC: {:.3f}'.format(rf_auc))\n",
    "# print('SVC의 AUC: {:.3f}'.format(svc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, xgb.predict_proba(X_test)[:, 1])\n",
    "\n",
    "plt.plot(fpr, tpr, label = 'ROC 곡선')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR (재현율)')\n",
    "# 0 근처의 임계값을 찾습니다.\n",
    "close_zero = np.argmin(np.abs(thresholds))\n",
    "plt.plot(fpr[close_zero], tpr[close_zero], 'o', markersize = 10,\n",
    "        label = '임계값 0', fillstyle = 'none', c = 'k', mew = 2)\n",
    "plt.legend(loc = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "xgb_auc = roc_auc_score(y_test, xgb.predict_proba(X_test)[:, 1])\n",
    "# svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))\n",
    "print('랜덤 포레스트의 AUC: {:.3f}'.format(xgb_auc))\n",
    "# print('SVC의 AUC: {:.3f}'.format(svc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 통계분석 (사용 데이터 : bike_marketing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) pop_density 변수를 factor형 변수로 변환하고, \n",
    "###     pop_density별 revenues의 평균 차이가 있는지 통계분석을 시행하여 결과를 해석하시오. \n",
    "###     만일 대립가설이 채택된다면 사후분석을 실시하고 결과를 해석하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/bike_marketing.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pop_density'] = df['pop_density'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "model = ols('revenues ~ C(pop_density)', df).fit()\n",
    "anova_lm(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 분산분석표를 통해 확인한 결과, SSA의 자유도는 2(집단의 수 -1 = 3-1), SST의 자유도는 169(관측값의 수 - 집단의 수 = 172-3)임을 확인할 수 있다. 분석 결과, p-value가 0.545로 유의수준 0.05하에서 대립가설을 기각한다. 따라서 세가지 인구밀집정도에 따른 매출은 통계적으로 유의한 차이를 가지고 있다고 보기 힘들다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) google_adwords, facebook, twitter, marketing_total, employees가 \n",
    "###     revenues에 영향을 미치는지 알아보는 회귀분석을 전진선택법을 사용하여 수행하고 결과를 해석하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(df['revenues'], df[['google_adwords', 'facebook', 'twitter', 'marketing_total', 'employees']]).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS.from_formula('revenues ~ google_adwords + facebook + twitter + marketing_total + employees', data = df).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3) 전진선택법을 사용해 변수를 선택한 후 새롭게 생성한 회귀모형에 대한 \n",
    "###     잔차분석을 수행하고 결과를 해석하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "\n",
    "#perform Durbin-Watson test\n",
    "durbin_watson(model.resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Durbin-Watson 검정 결과값이 2.11로 2에 가깝기 때문에 독립성 가정을 만족"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_test = stats.shapiro(model.resid)\n",
    "shapiro_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Shapiro-Wilk 검정 결과 p-value가 0.09로 유의수준 0.05에서 대립가설을 기각한다. 따라서 bike 데이터는 정규분포를 따른다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 잔차의 등분산성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = model.predict(df)\n",
    "residual = df['revenues'] - fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [1, 2, 5]\n",
    "\n",
    "zf=pd.DataFrame()\n",
    "# df 데이터프레임에서 특정 열을 선택하여 변수에 할당\n",
    "zf['a'] = np.array(a)\n",
    "zf['b'] = np.array(b)\n",
    "zf\n",
    "sns.regplot(x='a', y='b', data = zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zf = pd.DataFrame()\n",
    "zf['x'] = fitted\n",
    "zf['y'] = residual\n",
    "sns.regplot(x='x',y='y', data = zf, lowess=True, line_kws={'color': 'red'})\n",
    "plt.plot([fitted.min(), fitted.max()], [0, 0], '--', color='grey')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 잔차 vs fitted value(예측값)의 분포(등분산성 가정 확인)\n",
    "* 그래프의 기울기를 나타내는 빨간색 선이 포물선의 성향을 띠고 있기 때문에 잔차는 평균인 0을 중심으로 고르게 분포한다고 판단하기 어렵다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qqplot(정규성 가정 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.gofplots import qqplot\n",
    "qqplot(model.resid, line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* qqplot을 확인결과, 오른쪽 위를 향하는 45도 각도의 직선위에 그래프의 점들이 주로 위치한 것으로 보아 bike의 데이터가 정규성을 만족"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale_Location(등분산성 가정 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = stats.zscore(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf = pd.DataFrame()\n",
    "xf['x'] = fitted\n",
    "xf['y'] = np.sqrt(np.abs(sr))\n",
    "\n",
    "sns.regplot(x='x', y='y', data=xf, lowess=True, line_kws={'color': 'red'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 빨간선의 기울기가 0에 가까워야 하지만, fitted_value가 커질수록 기울기가 다소 변화하는 경향을 보이고있다. 이렇게 빨간선의 기울기가 0에서 떨어진 점이 있다면 해당 점에서는 표준화 잔차가 큼을 의미하고, 회귀 직선이 y값을 잘 적합하지 못함을 의미한다. 또한 해당 점들은 이상치일 가능성이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 극단값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import OLSInfluence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd, _ = OLSInfluence(model).cooks_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd.sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 비정형 데이터마이닝 (사용 데이터 : \"instagram_태교여행\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1) ‘instagram_태교여행.txt’ 데이터를 읽어온 뒤 숫자, 특수 문자 등을 \n",
    "###     제거하는 전처리 작업을 시행하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding = 'cp949') as f:\n",
    "        data = [line.split('\\t') for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_data('./data/instagram_태교여행.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(x for x in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(x for x in np.array(text).reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(text):\n",
    "    repl = ''\n",
    "    pattern  = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "    text = re.sub(pattern = pattern, repl = repl, string = text)\n",
    "    pattern  = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+'\n",
    "    text = re.sub(pattern = pattern, repl = repl, string = text)\n",
    "    pattern  = '([ㄱ-ㅎㅏ-ㅣ]+)'\n",
    "    text = re.sub(pattern = pattern, repl = repl, string = text)\n",
    "    pattern  = '<[^>]*>'\n",
    "    text = re.sub(pattern = pattern, repl = repl, string = text)\n",
    "    pattern = '[^\\w\\s]'\n",
    "    text = re.sub(pattern = pattern, repl = repl, string = text)\n",
    "    return text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = cleansing(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2) 전처리된 데이터에서 “태교여행”이란 단어를 사전에 추가하고 명사를 추출해 \n",
    "###     출현빈도 10위까지 막대그래프로 시각화하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taegyo = pd.DataFrame(columns = ['명사', '형태소'])\n",
    "taegyo['명사'] = ['태교여행']\n",
    "taegyo['형태소'] = ['NNP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taegyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taegyo.to_csv('./taegyo.txt', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab('C:/mecab/mecab-ko-dic')\n",
    "nouns = mecab.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(columns = ['명사', '빈도'])\n",
    "freq = cnt.most_common(10)\n",
    "temp_list = []\n",
    "temp_list2= []\n",
    "for i in freq:\n",
    "    temp_list.append(i[0])\n",
    "    temp_list2.append(i[1])\n",
    "temp_df['명사'] = temp_list\n",
    "temp_df['빈도'] = temp_list2\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "sns.barplot(x = '명사', y = '빈도', data = temp_df)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "for i in cnt.most_common(20):\n",
    "    words[i[0]] = i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "wordcloud = WordCloud(font_path = \"NanumGothicCoding.ttf\", background_color='white',colormap = \"Accent_r\",\n",
    "                      width=1500, height=1000).generate_from_frequencies(words)\n",
    "\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
