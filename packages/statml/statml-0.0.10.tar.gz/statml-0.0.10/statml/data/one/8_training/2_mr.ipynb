{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453a9747",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-기계학습(50점)\" data-toc-modified-id=\"1.-기계학습(50점)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. 기계학습(50점)</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1-데이터-탐색\" data-toc-modified-id=\"1.1-데이터-탐색-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1.1 데이터 탐색</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.1.2.-앞선-두-단계에서-얻은-향후-분석시-고려사항-작성\" data-toc-modified-id=\"1.1.2.-앞선-두-단계에서-얻은-향후-분석시-고려사항-작성-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>1.1.2. 앞선 두 단계에서 얻은 향후 분석시 고려사항 작성</a></span></li></ul></li><li><span><a href=\"#1.2-클래스-불균형을-처리하시오.\" data-toc-modified-id=\"1.2-클래스-불균형을-처리하시오.-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>1.2 클래스 불균형을 처리하시오.</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.1.-업-샘플링-과정-설명하고-결과-작성\" data-toc-modified-id=\"1.2.1.-업-샘플링-과정-설명하고-결과-작성-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>1.2.1. 업 샘플링 과정 설명하고 결과 작성</a></span></li><li><span><a href=\"#1.2.2-언더-샘플링-과정-설명하고-결과-작성\" data-toc-modified-id=\"1.2.2-언더-샘플링-과정-설명하고-결과-작성-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>1.2.2 언더 샘플링 과정 설명하고 결과 작성</a></span></li><li><span><a href=\"#1.2.3-둘-중-선택하고-이유-설명\" data-toc-modified-id=\"1.2.3-둘-중-선택하고-이유-설명-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>1.2.3 둘 중 선택하고 이유 설명</a></span></li></ul></li><li><span><a href=\"#1.3.-모델링-하시오\" data-toc-modified-id=\"1.3.-모델링-하시오-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>1.3. 모델링 하시오</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.1.-최소-3개-이상-알고리즘-제시하고-정확도-측면의-모델-1개와-속도-측면의-모델-1개를-꼭-구현(총-2개-이상)\" data-toc-modified-id=\"1.3.1.-최소-3개-이상-알고리즘-제시하고-정확도-측면의-모델-1개와-속도-측면의-모델-1개를-꼭-구현(총-2개-이상)-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>1.3.1. 최소 3개 이상 알고리즘 제시하고 정확도 측면의 모델 1개와 속도 측면의 모델 1개를 꼭 구현(총 2개 이상)</a></span></li><li><span><a href=\"#1.3.2.-모델-비교하고-결과-설명\" data-toc-modified-id=\"1.3.2.-모델-비교하고-결과-설명-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>1.3.2. 모델 비교하고 결과 설명</a></span></li><li><span><a href=\"#1.3.3.-속도-개선을-위한-차원-축소-설명하고-수행,-예측-성능과-속도-비교하고-결과-작성\" data-toc-modified-id=\"1.3.3.-속도-개선을-위한-차원-축소-설명하고-수행,-예측-성능과-속도-비교하고-결과-작성-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>1.3.3. 속도 개선을 위한 차원 축소 설명하고 수행, 예측 성능과 속도 비교하고 결과 작성</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c339826",
   "metadata": {},
   "source": [
    "## 1. 기계학습(50점)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc2031",
   "metadata": {},
   "source": [
    "### 1.1 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb479af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df1 = pd.read_csv('../data/diabetes_for_test.csv')\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de819cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diabetes = df1.groupby('Outcome').mean()\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504aa477",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(20, 14))\n",
    "for i in range(4) : \n",
    "    sns.barplot(diabetes.index,diabetes.iloc[:,i], ax = axes[0][i] )\n",
    "    axes[0][i].set_title(diabetes.columns[i])\n",
    "for i in range(4) : \n",
    "    sns.barplot(diabetes.index,diabetes.iloc[:,i+4], ax = axes[1][i])\n",
    "    axes[1][i].set_title(diabetes.columns[i+4])\n",
    "\n",
    "plt.suptitle(\"EDA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb64873",
   "metadata": {},
   "source": [
    "당뇨병이 있는 사람은 없는 사람보다 pregnancies의 평균 수치가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4947c",
   "metadata": {},
   "source": [
    "당뇨병이 있는 사람은 없는 사람 보다 Glucose의 평균 수치가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db041b3",
   "metadata": {},
   "source": [
    "당뇨병이 있는 사람은 없는 사람 보다 Insulin의 평균 수치가 높다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc206d1f",
   "metadata": {},
   "source": [
    "당뇨병이 있는 사람은 없는 사람 보다 BMI의 평균 수치가 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da75a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_cor = df1.drop(columns=[\"Outcome\"]).corr(method='pearson')\n",
    "sns.heatmap(df_cor,\n",
    "           xticklabels = df_cor.columns,\n",
    "           yticklabels = df_cor.columns,\n",
    "           cmap='RdBu_r',\n",
    "           annot=True, \n",
    "           linewidth=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b08259",
   "metadata": {},
   "source": [
    "Outcome을 제외한 변수들 간의 상관성을 보았을 때, 0.9 이상의 상관관계를 가지는 변수는 없었다. 그러므로 모든 변수를 사용하여 모델링해도 될 것으로 판단된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010cfd48",
   "metadata": {},
   "source": [
    "(2) 이상치를 식별하고 처리하시오. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458a8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d9f61",
   "metadata": {},
   "source": [
    "우선 describe로 변수들을 살펴보았을 때, 각 변수들의 결측치는 없는 것을 확인하였다. 이상치를 판단하기 위해서는 mean, min, max값을 확인하는 것이 좋다. 평균과 min, 평균과 max 값이 std에 비해 한참 차이가 난다면, 이상치가 있을 가능성이 높다. \n",
    "이러한 이상치를 정확히 판단하기 위해서는 아래와 같이 boxplot으로 시각화하여 보는 것이정확하다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df1.drop(columns=['Outcome'])\n",
    "df_v1 = pd.melt(X ,var_name='col', value_name='value')\n",
    "df_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30c372",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "sns.boxplot(x = 'col', y = 'value', data = df_v1)\n",
    "plt.xticks(range(8), X.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21231cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age의 중앙값 : \",  df1.Age.median()) \n",
    "outlier_index = df1[df1['Age']>400].index\n",
    "df1.loc[outlier_index,'Age']=df1.Age.median()\n",
    "\n",
    "sns.boxplot(df1[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d465965",
   "metadata": {},
   "source": [
    "Age 컬럼에 눈에띄는 이상치(999)가 있어 Age의 중앙값인 29 로 이상치를 대체한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad27dca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = df1[df1['Glucose']== 0].index\n",
    "df1.loc[outlier_index,'Glucose']=df1.Glucose.median()\n",
    "outlier_index = df1[df1['BloodPressure']== 0].index\n",
    "df1.loc[outlier_index,'BloodPressure']= df1.BloodPressure.median()\n",
    "\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae94507",
   "metadata": {},
   "source": [
    "추가적으로 데이터를 살펴 보았을 때, Glucose와 BloodPressure컬럼에는 0이 존재하지 않아야 된다고 판단되었다. 이를 이상치라고 판단하여 이상치를 제외한 중앙값으로 이상치를 대체하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f24554",
   "metadata": {},
   "source": [
    "#### 1.1.2. 앞선 두 단계에서 얻은 향후 분석시 고려사항 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58ba178",
   "metadata": {},
   "source": [
    "위에 describe() 함수를 보게 되면, 최솟값과 최댓값 차이가 많이 나는 컬럼이 존재한다. 따라서 선형모델 사용시 scale을 적용할 필요가 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf6c064",
   "metadata": {},
   "source": [
    "### 1.2 클래스 불균형을 처리하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9244393",
   "metadata": {},
   "source": [
    "#### 1.2.1. 업 샘플링 과정 설명하고 결과 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08acb6",
   "metadata": {},
   "source": [
    "Upsampling은 소수 클래스를 늘려서 다수 클래스 개수에 맞추는 방식으로,  \n",
    "대표적으로 random으로 소수의 클래스을 선택하여 데이터를 복제하는 RandomOverSampler, 임의의 소수 클래스 주변으로 새로운 데이터를 생성하는 smote 방식이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7acb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "X = df1.drop(['Outcome'],axis=1)\n",
    "y = df1[['Outcome']]\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "X_upsampling,y_upsampling = ros.fit_resample(X,y)\n",
    "\n",
    "print('기존의 타겟 분포')\n",
    "print(df1['Outcome'].value_counts()/len(df1))\n",
    "print('-'*10)\n",
    "print('upsampling의 타겟 분포')\n",
    "print(y_upsampling['Outcome'].value_counts()/len(y_upsampling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595e0ae",
   "metadata": {},
   "source": [
    "#### 1.2.2 언더 샘플링 과정 설명하고 결과 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dfd805",
   "metadata": {},
   "source": [
    "undersampling은 다수 클래스를 감소시켜 소수 클래스 개수에 맞추는 방식으로,  \n",
    "대표적으로 random으로 다수의 클래스의 데이터를 선택하여 삭제하는 RandomUnderSampler, 서로 다른 클래스가 있을 때 서로 다른 클래스끼리 가장 가까운 데이터들이 토멕링크로 묶여서 토멕링크 중 다수 클래스의 데이터를 제거하는 Tomek link방식이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656ac7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "rus = RandomOverSampler()\n",
    "X_undersampling,y_undersampling = rus.fit_resample(X,y)\n",
    "\n",
    "print('기존의 타겟 분포')\n",
    "print(df1['Outcome'].value_counts()/len(df1))\n",
    "print('-'*10)\n",
    "print('undersampling의 타겟 분포')\n",
    "print(y_undersampling['Outcome'].value_counts()/len(y_undersampling))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294106d",
   "metadata": {},
   "source": [
    "#### 1.2.3 둘 중 선택하고 이유 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f8fa3c",
   "metadata": {},
   "source": [
    "현 데이터가 총 768개로 적은 데이터가 존재한다.. 따라서, undersampling을 선택하게 되면 데이터가 더 적어지기 때문에 오버피팅이 일어날 위험이 더 크다.  \n",
    "**oversampling을 선택할 것 이다**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21eee57",
   "metadata": {},
   "source": [
    "### 1.3. 모델링 하시오"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a12e0da",
   "metadata": {},
   "source": [
    "#### 1.3.1. 최소 3개 이상 알고리즘 제시하고 정확도 측면의 모델 1개와 속도 측면의 모델 1개를 꼭 구현(총 2개 이상)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c52c74f",
   "metadata": {},
   "source": [
    "속도 측면에서 logisticregression,정확도 측면에서 svm, 기타로 xgboost를 제시한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e8fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.svm as svm\n",
    "\n",
    "log = LogisticRegression()\n",
    "xgb = XGBClassifier(random_state=0)\n",
    "svm_clf =svm.SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e9ae2",
   "metadata": {},
   "source": [
    "#### 1.3.2. 모델 비교하고 결과 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06151c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "## 5개의 경우의 수로 분할하여 검증 \n",
    "kfold = KFold()\n",
    "def model_result(model):\n",
    "    pred_li =[]\n",
    "    for train_index,test_index in kfold.split(X):\n",
    "        X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "        y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "        \n",
    "        X_train_resample,y_train_resample = smote.fit_resample(X_train,y_train)\n",
    "        \n",
    "        start = time.time()\n",
    "        model.fit(X_train_resample,y_train_resample)\n",
    "        end = time.time()\n",
    "        \n",
    "        pred = model.predict(X_test)\n",
    "        pred_li.append(accuracy_score(pred,y_test['Outcome']))\n",
    "        \n",
    "    ## 마지막 데이터 학습 속도     \n",
    "    print(f\"{end - start:.5f} sec\")\n",
    "    ## 5개의 train데이터에 대한 정확도의 평균 값  \n",
    "    print(np.mean(pred_li))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49f69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad912c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result(svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ae199",
   "metadata": {},
   "source": [
    "데이터 수가 적기 때문에 hold-out 기법이 아니라 cross-validation 기법으로 성능을 확인하였고, 위에서 말했던거와 같이 oversampling 기법인 smote를 활용하였다.  \n",
    "따라서, 역시나 logistic이 가장 빨랐으며 svm이 성능이 가장 좋은것을 확인할수있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275fb1db",
   "metadata": {},
   "source": [
    "#### 1.3.3. 속도 개선을 위한 차원 축소 설명하고 수행, 예측 성능과 속도 비교하고 결과 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c068036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_train = train_test_split(X,y, stratify=y, test_size=0.3, random_state=2022)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=8)\n",
    "X_train_pca = pca.fit(X_train_s)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_[:5].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c70167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_model_result(model):\n",
    "    pred_li =[]\n",
    "    for train_index,test_index in kfold.split(X):\n",
    "        X_train,X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "        y_train,y_test = y.iloc[train_index,:],y.iloc[test_index,:]\n",
    "        \n",
    "        X_train_resample,y_train_resample = smote.fit_resample(X_train,y_train)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_res_s = scaler.fit_transform(X_train_resample)\n",
    "        X_test_s = scaler.transform(X_test)\n",
    "        \n",
    "        pca = PCA(n_components=5)\n",
    "        X_train_pca = pca.fit_transform(X_train_res_s)\n",
    "        X_test_pca = pca.transform(X_test_s)\n",
    "        \n",
    "        start = time.time()\n",
    "        model.fit(X_train_pca,y_train_resample)\n",
    "        end = time.time()\n",
    "        \n",
    "        pred = model.predict(X_test_pca)\n",
    "        pred_li.append(accuracy_score(pred,y_test['Outcome']))\n",
    "        \n",
    "        \n",
    "    print(f\"{end - start:.5f} sec\")\n",
    "    print(np.mean(pred_li))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ecdd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model_result(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model_result(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model_result(svm_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50f4f98",
   "metadata": {},
   "source": [
    "예측 성능은 다소 상승되었고 속도 측면에도 차원축소에 의해 더 빨라졌다.  \n",
    "향후에 데이터가 크게 늘어난다면 성능 및 속도 측면에서 더 유의미한 차이가 클 것으로 보인다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
