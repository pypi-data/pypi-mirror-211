{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\[6\\]:\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 결측 처리<a href=\"#결측-처리\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## 결측 확인: isna와 notna<a href=\"#결측-확인:-isna와-notna\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[3\\]:\n",
    "\n",
    "    import pandas as pd\n",
    "    print(pd.isna([1, 2, np.nan]))\n",
    "    print(pd.notna([1, 2, np.nan]))\n",
    "\n",
    "    [False False  True]\n",
    "    [ True  True False]\n",
    "\n",
    "In \\[6\\]:\n",
    "\n",
    "    S = pd.Series([1,2,np.nan])\n",
    "    print(S.isna())\n",
    "    print(S.notna())\n",
    "\n",
    "    0    False\n",
    "    1    False\n",
    "    2     True\n",
    "    dtype: bool\n",
    "    0     True\n",
    "    1     True\n",
    "    2    False\n",
    "    dtype: bool\n",
    "\n",
    "## 결측치 대체 - fillna<a href=\"#결측치-대체---fillna\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "DataFrame.fillna(value=None, method=None, axis=None, inplace=False,\n",
    "limit=None, downcast=None)\n",
    "\n",
    "-   value: scalar, dict, Series, or DataFrame Value to use to fill holes\n",
    "    (e.g. 0), alternately a dict/Series/DataFrame of values specifying\n",
    "    which value to use for each index (for a Series) or column (for a\n",
    "    DataFrame). Values not in the dict/Series/DataFrame will not be\n",
    "    filled. This value cannot be a list  \n",
    "\n",
    "-   method: {‘backfill’, ‘bfill’, ‘pad’, ‘ffill’, None}, default None\n",
    "    Method to use for filling holes in reindexed Series pad / ffill:\n",
    "    propagate last valid observation forward to next valid backfill /\n",
    "    bfill: use next valid observation to fill gap.\n",
    "\n",
    "In \\[8\\]:\n",
    "\n",
    "    values = {\"A\": 0, \"B\": 1, \"C\": 2}\n",
    "    df = pd.DataFrame({\"A\":[3,np.nan], \"B\":[np.nan, 4], \"C\":[5, np.nan]})\n",
    "    df.fillna(value=values) # A의 결측은 0으로, B의 결측은 1로, C의 결측은 2로 대체\n",
    "\n",
    "Out\\[8\\]:\n",
    "\n",
    "|     | A   | B   | C   |\n",
    "|-----|-----|-----|-----|\n",
    "| 0   | 3.0 | 1.0 | 5.0 |\n",
    "| 1   | 0.0 | 4.0 | 2.0 |\n",
    "\n",
    "## 보간<a href=\"#보간\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "DataFrame.interpolate(method='linear', axis=0, limit=None,\n",
    "inplace=False, limit_direction=None, limit_area=None, downcast=None,\n",
    "\\*\\*kwargs)\n",
    "\n",
    "-   method: str, default ‘linear’ Interpolation technique to use. One\n",
    "    of:\n",
    "\n",
    "    -   'linear’: Ignore the index and treat the values as equally\n",
    "        spaced. This is the only method supported on MultiIndexes.\n",
    "\n",
    "    -   'time’: Works on daily and higher resolution data to interpolate\n",
    "        given length of interval.\n",
    "\n",
    "    -   'index’, ‘values’: use the actual numerical values of the index.\n",
    "\n",
    "    -   'pad’: Fill in NaNs using existing values.\n",
    "\n",
    "-   limit: int, optional Maximum number of consecutive NaNs to fill.\n",
    "    Must be greater than 0.\n",
    "\n",
    "## Imputer<a href=\"#Imputer\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "### Simple Imputer<a href=\"#Simple-Imputer\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "sklearn.impute.SimpleImputer(\\*, missing_values=nan, strategy='mean',\n",
    "fill_value=None, verbose=0, copy=True, add_indicator=False)\n",
    "\n",
    "-   missing_values: int, float, str, np.nan or None, default=np.nan The\n",
    "    placeholder for the missing values. All occurrences of\n",
    "    missing_values will be imputed. For pandas’ dataframes with nullable\n",
    "    integer dtypes with missing values, missing_values should be set to\n",
    "    np.nan, since pd.NA will be converted to np.nan.  \n",
    "      \n",
    "\n",
    "-   strategy: string, default=’mean’ The imputation strategy.\n",
    "\n",
    "    -   If “mean”, then replace missing values using the mean along each\n",
    "        column. Can only be used with numeric data.\n",
    "\n",
    "    -   If “median”, then replace missing values using the median along\n",
    "        each column. Can only be used with numeric data.\n",
    "\n",
    "    -   If “most_frequent”, then replace missing using the most frequent\n",
    "        value along each column. Can be used with strings or numeric\n",
    "        data. If there is more than one such value, only the smallest is\n",
    "        returned.\n",
    "\n",
    "### KNN IMputer<a href=\"#KNN-IMputer\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class sklearn.impute.KNNImputer(\\*, missing_values=nan, n_neighbors=5,\n",
    "weights='uniform', metric='nan_euclidean', copy=True,\n",
    "add_indicator=False)\n",
    "\n",
    "# 특징 선택 및 차원 축소<a href=\"#특징-선택-및-차원-축소\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## Select KBest<a href=\"#Select-KBest\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class sklearn.feature_selection.SelectKBest(score_func=\\<function\n",
    "f_classif>, \\*, k=10)\n",
    "\n",
    "-   f_classif: ANOVA F-value between label/feature for classification\n",
    "    tasks.\n",
    "-   mutual_info_classif: Mutual information for a discrete target.\n",
    "-   chi2: Chi-squared stats of non-negative features for classification\n",
    "    tasks.\n",
    "-   f_regression:F-value between label/feature for regression tasks.\n",
    "-   mutual_info_regression: Mutual information for a continuous target.\n",
    "-   SelectPercentile: Select features based on percentile of the highest\n",
    "    scores.\n",
    "-   SelectFpr: Select features based on a false positive rate test.\n",
    "-   SelectFdr: Select features based on an estimated false discovery\n",
    "    rate.\n",
    "-   SelectFwe: Select features based on family-wise error rate.\n",
    "-   GenericUnivariateSelect: Univariate feature selector with\n",
    "    configurable mode.\n",
    "\n",
    "Method\n",
    "\n",
    "-   get_support: Get a mask, or integer index, of the features selected\n",
    "-   fit(X, y): Run score function on (X, y) and get the appropriate\n",
    "    features.\n",
    "\n",
    "## PCA<a href=\"#PCA\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class sklearn.decomposition.PCA(n_components=None, \\*, copy=True,\n",
    "whiten=False, svd_solver='auto', tol=0.0, iterated_power='auto',\n",
    "random_state=None)\n",
    "\n",
    "-   n_componentsint, float or ‘mle’, default=None: Number of components\n",
    "    to keep\n",
    "\n",
    "Atributes\n",
    "\n",
    "-   components\\_: ndarray of shape (n_components, n_features) Principal\n",
    "    axes in feature space, representing the directions of maximum\n",
    "    variance in the data. The components are sorted by\n",
    "    explained*variance*.\n",
    "\n",
    "-   explained*variance*: ndarray of shape (n_components,) The amount of\n",
    "    variance explained by each of the selected components. The variance\n",
    "    estimation uses n_samples - 1 degrees of freedom.\n",
    "\n",
    "-   explained_variance*ratio*: ndarray of shape (n_components,)\n",
    "    Percentage of variance explained by each of the selected components.\n",
    "\n",
    "-   singular*values*: ndarray of shape (n_components,) The singular\n",
    "    values corresponding to each of the selected components. The\n",
    "    singular values are equal to the 2-norms of the n_components\n",
    "    variables in the lower-dimensional space.\n",
    "\n",
    "# 클래스 불균형<a href=\"#클래스-불균형\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## SMOTE<a href=\"#SMOTE\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class imblearn.over_sampling.SMOTE(\\*, sampling_strategy='auto',\n",
    "random_state=None, k_neighbors=5, n_jobs=None)\n",
    "\n",
    "Parameters\n",
    "\n",
    "-   sampling_strategy: float, str, dict or callable, default=’auto’\n",
    "\n",
    "    -   When float, it corresponds to the desired ratio of the number of\n",
    "        samples in the minority class over the number of samples in the\n",
    "        majority class after resampling. Therefore, the ratio is\n",
    "        expressed as \\\\alpha*{os} = N*{rm} / N*{M} where N*{rm} is the\n",
    "        number of samples in the minority class after resampling and\n",
    "        N\\_{M} is the number of samples in the majority class.\n",
    "\n",
    "    -   When str, specify the class targeted by the resampling. The\n",
    "        number of samples in the different classes will be equalized.\n",
    "        Possible choices are:\n",
    "\n",
    "        -   'minority': resample only the minority class;\n",
    "\n",
    "        -   'not minority': resample all classes but the minority class;\n",
    "\n",
    "        -   'not majority': resample all classes but the majority class;\n",
    "\n",
    "        -   'all': resample all classes;\n",
    "\n",
    "        -   'auto': equivalent to 'not majority'.\n",
    "\n",
    "    -   When dict, the keys correspond to the targeted classes. The\n",
    "        values correspond to the desired number of samples for each\n",
    "        targeted class.\n",
    "\n",
    "-   k_neighborsint or object, default=5 If int, number of nearest\n",
    "    neighbours to used to construct synthetic samples. If object, an\n",
    "    estimator that inherits from KNeighborsMixin that will be used to\n",
    "    find the k_neighbors.\n",
    "\n",
    "Method\n",
    "\n",
    "-   fit_resample(X, y): Resample the dataset.\n",
    "\n",
    "## NearMiss<a href=\"#NearMiss\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class imblearn.under_sampling.NearMiss(\\*, sampling_strategy='auto',\n",
    "version=1, n_neighbors=3, n_neighbors_ver3=3, n_jobs=None)\n",
    "\n",
    "-   sampling_strategy: float, str, dict, callable, default=’auto’(SMOTE\n",
    "    참고)\n",
    "\n",
    "-   version: int, default=1\n",
    "\n",
    "    -   Version of the NearMiss to use. Possible values are 1, 2 or 3.\n",
    "\n",
    "-   n_neighbors: int default=3\n",
    "\n",
    "## Random<a href=\"#Random\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "class imblearn.under_sampling.RandomUnderSampler(\\*,\n",
    "sampling_strategy='auto', random_state=None, replacement=False)\n",
    "\n",
    "class imblearn.over_sampling.RandomOverSampler(\\*,\n",
    "sampling_strategy='auto', random_state=None, shrinkage=None)\n",
    "\n",
    "# 특수 데이터 타입의 Attributes<a href=\"#특수-데이터-타입의-Attributes\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "## dt<a href=\"#dt\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Series.dt.date Returns numpy array of python datetime.date objects\n",
    "    (namely, the date part of Timestamps without timezone information).\n",
    "-   Series.dt.time Returns numpy array of datetime.time.\n",
    "-   Series.dt.year The year of the datetime\n",
    "-   Series.dt.month The month as January=1, December=12\n",
    "-   Series.dt.day The days of the datetime\n",
    "-   Series.dt.hour The hours of the datetime\n",
    "-   Series.dt.minute The minutes of the datetime\n",
    "-   Series.dt.second The seconds of the datetime\n",
    "-   Series.dt.week The week ordinal of the year\n",
    "-   Series.dt.weekofyear The week ordinal of the year\n",
    "-   Series.dt.dayofweek The day of the week with Monday=0, Sunday=6\n",
    "-   Series.dt.weekday The day of the week with Monday=0, Sunday=6\n",
    "-   Series.dt.weekday_name The name of day in a week (ex: Friday)\n",
    "-   Series.dt.dayofyear The ordinal day of the year\n",
    "-   Series.dt.quarter The quarter of the date\n",
    "\n",
    "## str<a href=\"#str\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "-   Series.str.contains(pat\\[, case, flags, na, ...\\]) Return boolean\n",
    "    Series/array whether given pattern/regex is contained in each string\n",
    "    in the Series/Index.\n",
    "-   Series.str.endswith(pat\\[, na\\]) Return boolean Series indicating\n",
    "    whether each string in the Series/Index ends with passed pattern.\n",
    "-   Series.str.len() Compute length of each string in the Series/Index.\n",
    "-   Series.str.split(\\[pat, n, expand\\]) Split each string (a la\n",
    "    re.split) in the Series/Index by given pattern, propagating NA\n",
    "    values.\n",
    "-   Series.str.isalnum() Check whether all characters in each string in\n",
    "    the Series/Index are alphanumeric.\n",
    "-   Series.str.isalpha() Check whether all characters in each string in\n",
    "    the Series/Index are alphabetic.\n",
    "-   Series.str.isdigit() Check whether all characters in each string in\n",
    "    the Series/Index are digits.\n",
    "\n",
    "# Time 변수 관련 처리<a href=\"#Time-변수-관련-처리\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "In \\[11\\]:\n",
    "\n",
    "    pd.to_datetime(\"2010/11/12\")\n",
    "\n",
    "Out\\[11\\]:\n",
    "\n",
    "    Timestamp('2010-11-12 00:00:00')\n",
    "\n",
    "In \\[10\\]:\n",
    "\n",
    "    pd.date_range(\"2018-01-01\", periods=5, freq=\"H\")\n",
    "\n",
    "Out\\[10\\]:\n",
    "\n",
    "    DatetimeIndex(['2018-01-01 00:00:00', '2018-01-01 01:00:00',\n",
    "                   '2018-01-01 02:00:00', '2018-01-01 03:00:00',\n",
    "                   '2018-01-01 04:00:00'],\n",
    "                  dtype='datetime64[ns]', freq='H')\n",
    "\n",
    "In \\[12\\]:\n",
    "\n",
    "    pd.to_datetime(\"2010/11/12\") + pd.to_timedelta(1, unit = \"h\")\n",
    "\n",
    "Out\\[12\\]:\n",
    "\n",
    "    Timestamp('2010-11-12 01:00:00')\n",
    "\n",
    "# groupby<a href=\"#groupby\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "DataFrame.groupby(by=None, axis=0, level=None, as_index=True, sort=True,\n",
    "group_keys=True, squeeze=, observed=False, dropna=True)\n",
    "\n",
    "DataFrameGroupBy.agg(arg, \\*args, \\*\\*kwargs)\n",
    "\n",
    "-   func : callable, string, dictionary, or list of string/callables\n",
    "\n",
    "    Function to use for aggregating the data. If a function, must either\n",
    "    work when passed a DataFrame or when passed to DataFrame.apply. For\n",
    "    a DataFrame, can pass a dict, if the keys are DataFrame column\n",
    "    names.\n",
    "\n",
    "    -   Accepted Combinations are:\n",
    "        -   string function name\n",
    "        -   function\n",
    "        -   list of functions\n",
    "        -   dict of column names -> functions (or list of functions)\n",
    "\n",
    "예시\n",
    "\n",
    "-   df.groupby('A').agg(\\['min', 'max'\\])\n",
    "-   df.groupby('A').agg({'B': \\['min', 'max'\\], 'C': 'sum'})\n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:\n",
    "\n",
    "     \n",
    "\n",
    "In \\[ \\]:"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
