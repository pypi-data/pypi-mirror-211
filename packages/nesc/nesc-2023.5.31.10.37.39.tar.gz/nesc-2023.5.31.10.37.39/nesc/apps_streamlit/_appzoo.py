import streamlit as st

from meutils.pipe import *


###############################################
@st.experimental_singleton()
def lac_obj():
    from meutils.notice.wecom import Wecom

    Wecom().send_markdown('åŠ è½½lac')

    from LAC import LAC

    lac = LAC(mode='lac')
    return lac


@st.experimental_singleton()
def s2v_obj(model_home):
    return Simbert2vec(model_home)


lac = lac_obj()
#################################################
st.sidebar.markdown('**ğŸ”¥åº”ç”¨é›†æˆğŸ”¥**')

app_name = st.sidebar.selectbox('AI', ('å­—æ®µæ¨¡ç³ŠåŒ¹é…', 'å­—æ®µç¿»è¯‘', 'çˆ¬è™«å·¥å…·', 'ä¼å¾®æœºå™¨äºº', 'OCR', 'æ•°æ®å®‰å…¨è¯„åˆ†', 'docs'), index=1)
Path(app_name).mkdir(exist_ok=True)

if app_name == 'docs':
    st.markdown('# AI åº”ç”¨é›†æˆ')
    st.markdown('## è¯­ä¹‰åŒ¹é…')
    st.markdown('## OCR')


elif app_name == 'å­—æ®µæ¨¡ç³ŠåŒ¹é…':
    st.markdown(f'##### {app_name}')

    topn = st.sidebar.slider('å¬å›TopN', min_value=1, max_value=20, value=1)

    s2 = set(st.sidebar.text_area('ç›®æ ‡å­—æ®µ', 'æ²»ç†æ•°æ®', height=300).strip().split('\n'))
    s1 = set(st.text_area('å¾…åŒ¹é…å­—æ®µ', 'æ•°æ®æ²»ç†', height=300).strip().split('\n'))

    is_run = st.button('å¼€å§‹ğŸ”¥')
    if is_run:
        from simv2 import *

        model_home = 'chinese_roformer-sim-char-ft_L-6_H-384_A-6'
        batch_size = 512


        def bert_vector(s1, s2, batch_size=batch_size, model_home='chinese_roformer-sim-char-ft_L-6_H-384_A-6'):
            w2v = get_vector_cache()
            s = (s1 | s2) - set(w2v)

            if s:
                s2v = s2v_obj(model_home)

                # s2v = Simbert2vec(model_home)

                my_bar = st.progress(0)
                _iter = list(s) | xgroup(batch_size)
                with st.spinner("å‘é‡åŒ– ..."):

                    for idx, ws in tqdm(enumerate(_iter, 1), 'å‘é‡åŒ–'):
                        my_bar.progress(idx / len(_iter))
                        vs = s2v.encoder(ws, output_dim=None)
                        w2v.update(zip(ws, vs))  # å‘é‡å…¨é›†

                joblib.dump(w2v, 'cache.pkl')  # æ›´æ–°cache

            return w2v


        w2v = bert_vector(s1, s2, batch_size, model_home)

        i2w_1, data1 = get_i2w_vecs(s1, w2v)
        i2w_2, data2 = get_i2w_vecs(s2, w2v)

        ann = ANN()
        ann.train(data2, metric=0)

        diss, idxs = ann.search(data1, topn)

        df_rst = get_rst(i2w_1, i2w_2, diss, idxs)
        df_rst.columns = ['target', 'recall', 'score']

        # ä¸‹è½½
        # csv = df_rst.to_csv(sep='\t', index=False, header=False).encode('utf-8')

        # st.download_button(
        #     label="ä¸‹è½½å¬å›ç»“æœ",
        #     data=csv,
        #     file_name='recall.tsv',
        #     mime='text/csv',
        # )

        filename = f"{app_name}/{time.time()}.xlsx"
        df_rst.to_excel(filename)

        with open(filename, 'rb') as f:
            data = f.read()

            st.download_button(
                label="ä¸‹è½½ğŸ¥º",
                data=data,
                file_name='recall.xlsx',
                mime='application/octet-stream',
            )

        st.dataframe(df_rst.head(10), 4000, 3000)

elif app_name == 'å­—æ®µç¿»è¯‘':
    st.markdown(f'##### {app_name}')

    io = st.sidebar.file_uploader('ä¸Šä¼ è¯æ ¹å­—å…¸ï¼ˆé»˜è®¤æ—§å­—å…¸å¯ä¸Šä¼ æ›´æ–°ï¼‰')
    targets = set(st.text_area('å¾…ç¿»è¯‘å­—æ®µ', 'å…¬å‹ŸåŸºé‡‘', height=300).strip().split('\n'))

    if io is None:
        io = 'å­—æ®µè¯æ ¹å­—å…¸ï¼ˆå¾æ±‚æ„è§ç¨¿ï¼‰.xlsx'

    df = pd.read_excel(io)[['ä¸­æ–‡å…¨ç§°', 'è‹±æ–‡åç§°', 'è‹±æ–‡ç®€ç§°']]
    df['ä¸­æ–‡å…¨ç§°'] = df['ä¸­æ–‡å…¨ç§°'].str.split('/')
    df = df.explode('ä¸­æ–‡å…¨ç§°')

    # # è‡ªå®šä¹‰åˆ†å‰²è¯
    # lac.add_word(' '.join(df['ä¸­æ–‡å…¨ç§°'].to_list())) # æœ‰bugï¼Œæ²¡åŒºåˆ†å‡º

    for w in set(df['ä¸­æ–‡å…¨ç§°'].append(pd.read_csv('words.txt', names=['w'])['w'].astype(str))):
        lac.add_word(w)

    is_run = st.button('å¼€å§‹ğŸ”¥')
    if is_run:
        rst = []
        for t in targets:
            t_ = t
            t = lac.run(t)[0]

            åˆ†è¯ = []
            è‹±æ–‡åç§° = []
            è‹±æ–‡ç®€ç§° = []
            for w in t:
                if w == t_:
                    continue
                df_r = df[df['ä¸­æ–‡å…¨ç§°'] == w]
                if len(df_r):
                    _ = df_r[:1].values[0]  # æ—¥æœŸ', 'DATE', 'DT', 2

                    è‹±æ–‡åç§°.append(_[1])
                    è‹±æ–‡ç®€ç§°.append(_[2])
                else:
                    è‹±æ–‡åç§°.append(w)
                    è‹±æ–‡ç®€ç§°.append(w)

            rst.append([t_, t, ' '.join(è‹±æ–‡åç§°), '_'.join(è‹±æ–‡ç®€ç§°)])

        df_rst = pd.DataFrame(rst, columns=['ä¸­æ–‡å­—æ®µ', 'åˆ†è¯', 'è‹±æ–‡åç§°', 'è‹±æ–‡ç®€ç§°'])
        # csv = df_rst.to_csv(sep='\t', index=False, header=False).encode('utf-8')

        filename = f"{app_name}/{time.time()}.xlsx"
        df_rst.to_excel(filename)

        with open(filename, 'rb') as f:
            data = f.read()

            st.download_button(
                label="ä¸‹è½½ğŸ¥º",
                data=data,
                file_name='è¯æ ¹ç¿»è¯‘ç»“æœ.xlsx',
                mime='application/octet-stream',
            )

        st.dataframe(df_rst.head(10), 4000, 3000)

elif app_name == 'çˆ¬è™«å·¥å…·':
    from meutils.request_utils.crawler import Crawler

    url = st.text_input('url', 'https://top.baidu.com/board?tab=realtime')
    xpath = st.text_input('xpath', '//*[@id="sanRoot"]/main/div[2]/div/div[2]/div[*]/div[2]/a/div[1]//text()')

    c = Crawler('https://top.baidu.com/board?tab=realtime')
    st.json(c.xpath(xpath))

# ç»´æŠ¤äºº
users = 'yuanjie@nesc.cn,liufeng@nesc.cn'.split(',')
st.sidebar.multiselect('ç»´æŠ¤äºº', users, users)
