#!/usr/bin/env python
# -*- coding: utf-8 -*-
# @Project      : nesc.
# @File         : apps
# @Time         : 2021/11/12 ä¸‹åˆ3:18
# @Author       : yuanjie
# @WeChat       : 313303303
# @Software     : PyCharm
# @Description  :


import streamlit as st

from meutils.pipe import *
from meutils.request_utils.crawler import Crawler
from meutils.decorators.decorator import decorator
from meutils.notice.wecom import Wecom

from nesc.sim.simv2 import *


##################################################################
@st.experimental_singleton()
def lac_obj():
    Wecom().send_markdown('åŠ è½½lac')

    from LAC import LAC

    lac = LAC(mode='lac')
    return lac


lac = lac_obj()


@st.experimental_singleton()
def s2v_obj(model_home):
    return Simbert2vec(model_home)


def download_excel(df, app_name, file_name='è¯æ ¹ç¿»è¯‘ç»“æœ.xlsx'):
    filename = f"{app_name}/{time.time()}.xlsx"
    df.to_excel(filename)

    with open(filename, 'rb') as f:
        data = f.read()

        st.download_button(
            label="ä¸‹è½½ğŸ¥º",
            data=data,
            file_name=file_name,
            mime='application/octet-stream',
        )

    st.dataframe(df.head(10), 4000, 3000)


##################################################################


@decorator
def app_info(f, desc='', *args, **kwargs):
    app_name = f.__name__
    Path(app_name).mkdir(exist_ok=True)

    st.markdown(f'##### {app_name}')
    st.markdown(f'**{desc}**')

    return f(*args, **kwargs)


@app_info()
def çˆ¬è™«å·¥å…·():
    url = st.text_input('url', 'https://top.baidu.com/board?tab=realtime')
    xpath = st.text_input('xpath', '//*[@id="sanRoot"]/main/div[2]/div/div[2]/div[*]/div[2]/a/div[1]//text()')

    c = Crawler(url)
    st.json(c.xpath(xpath))


@app_info()
def å­—æ®µç¿»è¯‘():
    io = st.sidebar.file_uploader('ä¸Šä¼ è¯æ ¹å­—å…¸ï¼ˆé»˜è®¤æ—§å­—å…¸å¯ä¸Šä¼ æ›´æ–°ï¼‰')
    targets = set(st.text_area('å¾…ç¿»è¯‘å­—æ®µ', 'å…¬å‹ŸåŸºé‡‘', height=300).strip().split('\n'))

    if io is None:
        io = '/root/model/bert/å­—æ®µè¯æ ¹å­—å…¸ï¼ˆå¾æ±‚æ„è§ç¨¿ï¼‰.xlsx'

    df = pd.read_excel(io)[['ä¸­æ–‡å…¨ç§°', 'è‹±æ–‡åç§°', 'è‹±æ–‡ç®€ç§°']]
    df['ä¸­æ–‡å…¨ç§°'] = df['ä¸­æ–‡å…¨ç§°'].str.split('/')
    df = df.explode('ä¸­æ–‡å…¨ç§°')

    # # è‡ªå®šä¹‰åˆ†å‰²è¯
    # lac.add_word(' '.join(df['ä¸­æ–‡å…¨ç§°'].to_list())) # æœ‰bugï¼Œæ²¡åŒºåˆ†å‡º

    for w in set(df['ä¸­æ–‡å…¨ç§°'].append(pd.read_csv('/root/model/bert/words.txt', names=['w'])['w'].astype(str))):
        lac.add_word(w)

    is_run = st.button('å¼€å§‹ğŸ”¥')

    if is_run:
        rst = []
        for t in targets:
            t_ = t
            t = lac.run(t)[0]

            è‹±æ–‡åç§° = []
            è‹±æ–‡ç®€ç§° = []
            for w in t:
                if w == t_:
                    continue
                df_r = df[df['ä¸­æ–‡å…¨ç§°'] == w]
                if len(df_r):
                    _ = df_r[:1].values[0]  # æ—¥æœŸ', 'DATE', 'DT', 2

                    è‹±æ–‡åç§°.append(_[1])
                    è‹±æ–‡ç®€ç§°.append(_[2])
                else:
                    è‹±æ–‡åç§°.append(w)
                    è‹±æ–‡ç®€ç§°.append(w)

            rst.append([t_, t, ' '.join(è‹±æ–‡åç§°), '_'.join(è‹±æ–‡ç®€ç§°)])

        df_rst = pd.DataFrame(rst, columns=['ä¸­æ–‡å­—æ®µ', 'åˆ†è¯', 'è‹±æ–‡åç§°', 'è‹±æ–‡ç®€ç§°'])

        download_excel(df_rst)


@app_info()
def å­—æ®µæ¨¡ç³ŠåŒ¹é…():
    topn = st.sidebar.slider('å¬å›TopN', min_value=1, max_value=20, value=1)

    s2 = set(st.sidebar.text_area('ç›®æ ‡å­—æ®µ', 'æ²»ç†æ•°æ®', height=300).strip().split('\n'))
    s1 = set(st.text_area('å¾…åŒ¹é…å­—æ®µ', 'æ•°æ®æ²»ç†', height=300).strip().split('\n'))

    is_run = st.button('å¼€å§‹ğŸ”¥')
    if is_run:

        model_home = 'chinese_roformer-sim-char-ft_L-6_H-384_A-6'
        batch_size = 512

        def bert_vector(s1, s2, batch_size=batch_size, model_home='chinese_roformer-sim-char-ft_L-6_H-384_A-6'):
            w2v = get_vector_cache()
            s = (s1 | s2) - set(w2v)

            if s:
                s2v = s2v_obj(model_home)

                my_bar = st.progress(0)
                _iter = list(s) | xgroup(batch_size)
                with st.spinner("å‘é‡åŒ– ..."):

                    for idx, ws in tqdm(enumerate(_iter, 1), 'å‘é‡åŒ–'):
                        my_bar.progress(idx / len(_iter))
                        vs = s2v.encoder(ws, output_dim=None)
                        w2v.update(zip(ws, vs))  # å‘é‡å…¨é›†

                joblib.dump(w2v, 'cache.pkl')  # æ›´æ–°cache

            return w2v

        w2v = bert_vector(s1, s2, batch_size, model_home)

        i2w_1, data1 = get_i2w_vecs(s1, w2v)
        i2w_2, data2 = get_i2w_vecs(s2, w2v)

        ann = ANN()
        ann.train(data2, metric=0)

        diss, idxs = ann.search(data1, topn)

        df_rst = get_rst(i2w_1, i2w_2, diss, idxs)
        df_rst.columns = ['target', 'recall', 'score']
        download_excel(df_rst)


@app_info()
def æ•°æ®åˆ†çº§é¢„æµ‹():
    pass


@app_info()
def æ•°æ®åˆ†ç±»é¢„æµ‹():
    pass
